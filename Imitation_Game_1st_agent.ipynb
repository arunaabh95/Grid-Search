{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunaabh95/Grid-Search/blob/main/Imitation_Game_1st_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eTMd_S0bdul"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwfgxwxlTeP7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ast import literal_eval\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAYbzMiuuAJD"
      },
      "outputs": [],
      "source": [
        "#df1 = pd.read_csv('/content/contentgdrive/MyDrive/data-520/data.csv')\n",
        "filename = '/content/train-prob-1.h5'\n",
        "df1 = pd.read_hdf(filename, key = 'df', mode='r')\n",
        "print(df1.shape)\n",
        "\n",
        "# test data\n",
        "test_file = '/content/test-1.h5'\n",
        "df2 = pd.read_hdf(test_file, mode='r')\n",
        "print(df2.shape)\n",
        "\n",
        "# validation data\n",
        "validation_file = '/content/validate-1.h5'\n",
        "df3 = pd.read_hdf(validation_file, mode='r')\n",
        "print(df3.shape)\n",
        "\n",
        "df1 = shuffle(df1)\n",
        "df2 = shuffle(df2)\n",
        "df3 = shuffle(df3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcwrqidtb2Nw"
      },
      "outputs": [],
      "source": [
        "# Preprocessing data\n",
        "\n",
        "def make_grid(probability, size):\n",
        "  grid = np.zeros((size, size))\n",
        "  if probability == 0:\n",
        "    return grid\n",
        "  for i in range(0, size - 1):\n",
        "    for j in range(0, size - 1):\n",
        "      p0 = random.uniform(0, 1)\n",
        "      if probability > p0:\n",
        "          grid[i][j] = 1\n",
        "\n",
        "  grid[0][0] = 0\n",
        "  grid[size - 1][size - 1] = 0\n",
        "  return grid\n",
        "\n",
        "def preprocess_single(pos):\n",
        "  g = make_grid(0,50)\n",
        "  g[pos[0]][pos[1]] = 1\n",
        "  return g\n",
        "\n",
        "def preprocess(input):\n",
        "  i = 0\n",
        "  toRet = np.empty((len(input),50,50))\n",
        "  for pos in input:\n",
        "    toRet[i] = preprocess_single(pos)\n",
        "    i += 1\n",
        "  return toRet\n",
        "\n",
        "#start = preprocess(df1.iloc[0:10000:,0])\n",
        "start_test = preprocess(df2.iloc[0:30000:,0])\n",
        "start_validation = preprocess(df3.iloc[0:30000:,0])\n",
        "#start.shape\n",
        "\n",
        "# train\n",
        "#start = np.vstack(start.apply(np.array).to_numpy()).reshape(100000,2)\n",
        "# grid = np.vstack(df1.iloc[0:10000:,1].apply(np.array).to_numpy()).reshape(10000,50,50)\n",
        "# move = df1.iloc[0:10000:,2].apply(str).to_numpy()\n",
        "\n",
        "#test\n",
        "#start_test = np.vstack(df2.iloc[0:20000:,0].apply(np.array).to_numpy()).reshape(20000,2)\n",
        "grid_test = np.vstack(df2.iloc[0:30000:,1].apply(np.array).to_numpy()).reshape(30000,50,50)\n",
        "move_test = df2.iloc[0:30000:,2].apply(str).to_numpy()\n",
        "\n",
        "# validation\n",
        "#start_validation = np.vstack(df3.iloc[0:20000:,0].apply(np.array).to_numpy()).reshape(20000,2)\n",
        "grid_validation = np.vstack(df3.iloc[0:30000:,1].apply(np.array).to_numpy()).reshape(30000,50,50)\n",
        "move_validation = df3.iloc[0:30000:,2].apply(str).to_numpy()\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "#One hot encoding\n",
        "\n",
        "# encode test data\n",
        "test_values = np.array(move_test)\n",
        "test_integer_encoded = label_encoder.fit_transform(test_values)\n",
        "# binary encode\n",
        "test_integer_encoded = test_integer_encoded.reshape(len(test_integer_encoded), 1)\n",
        "onehot_encoded_test = onehot_encoder.fit_transform(test_integer_encoded)\n",
        "print(onehot_encoded_test.shape)\n",
        "\n",
        "# encode validation data\n",
        "validation_values = np.array(move_validation)\n",
        "validation_integer_encoded = label_encoder.fit_transform(validation_values)\n",
        "# binary encode\n",
        "validation_integer_encoded = validation_integer_encoded.reshape(len(validation_integer_encoded), 1)\n",
        "onehot_encoded_validation = onehot_encoder.fit_transform(validation_integer_encoded)\n",
        "#onehot_encoded_validation = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(onehot_encoded_validation))\n",
        "\n",
        "print(onehot_encoded_validation.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK4gnWGSU4fj"
      },
      "outputs": [],
      "source": [
        "epochs=100\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "input_start = tf.keras.Input(shape=(50,50), name=\"start\")\n",
        "input_grid = tf.keras.Input(shape=(50,50), name=\"grid\")\n",
        "\n",
        "x = tf.keras.layers.Dense(512,input_dim=2,activation='relu')(input_start)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "y = tf.keras.layers.Dense(512,input_dim=2,activation='relu')(input_grid)\n",
        "y = tf.keras.layers.Flatten()(y)\n",
        "z = tf.keras.layers.Concatenate()([x,y])\n",
        "z = tf.keras.layers.Dropout(0.8)(z)\n",
        "z = tf.keras.layers.Dense(512, activation='relu')(z)\n",
        "z = tf.keras.layers.Dropout(0.8)(z)\n",
        "#z = tf.keras.layers.Dense(128, activation='relu')(z)\n",
        "z = tf.keras.layers.Dense(128, kernel_regularizer=tf.keras.regularizers.l1(1e-5),activation='relu')(z)\n",
        "z = tf.keras.layers.Dense(4, activation = 'softmax')(z)\n",
        "model = tf.keras.models.Model(inputs=[input_start, input_grid], outputs=z)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=1e-3),metrics=['accuracy'])\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('agent-1', monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNE4_GQuf1kU"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "def train():\n",
        "  for i in range(5):\n",
        "    print(i, \"th iteration\")\n",
        "    first = (i*10000 + 1)\n",
        "    last = (i + 1) * 10000\n",
        "    start = preprocess(df1.iloc[first:last:,0]) \n",
        "    grid = np.vstack(df1.iloc[first:last:,1].apply(np.array).to_numpy()).reshape(9999,50,50)\n",
        "    move = df1.iloc[first:last:,2].apply(str).to_numpy()\n",
        "    # encode train data\n",
        "    values = np.array(move)\n",
        "    integer_encoded = label_encoder.fit_transform(values)\n",
        "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded).astype(int)\n",
        "    #onehot_encoded = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(onehot_encoded))\n",
        "    print(onehot_encoded.shape)\n",
        "    model_history = model.fit((start, grid), \n",
        "                         onehot_encoded, \n",
        "                          epochs=epochs,\n",
        "                          callbacks=callbacks_list,\n",
        "                          batch_size=256, \n",
        "                          verbose=1)\n",
        "    \n",
        "train()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "\n",
        "first = 600000\n",
        "last = 700000\n",
        "start = preprocess(df1.iloc[first:last:,0]) \n",
        "grid = np.vstack(df1.iloc[first:last:,1].apply(np.array).to_numpy()).reshape(100000,50,50)\n",
        "move = df1.iloc[first:last:,2].apply(str).to_numpy()\n",
        "# encode train data\n",
        "values = np.array(move)\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded).astype(int)\n",
        "#onehot_encoded = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(onehot_encoded))\n",
        "\n",
        "model_history = model.fit((start, grid), \n",
        "                          onehot_encoded, \n",
        "                          epochs=epochs, \n",
        "                          batch_size=2048, \n",
        "                          verbose=1,\n",
        "                          validation_data=((start_validation, grid_validation), onehot_encoded_validation))\n",
        "\n",
        "\n",
        "model.save('agent-1')"
      ],
      "metadata": {
        "id": "3_xKRkuLtILl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRWPbd6hf1Wz"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate((start_test, grid_test), onehot_encoded_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# Plot the loss function\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
        "ax.plot(np.sqrt(model_history.history['loss']), 'r', label='train')\n",
        "ax.plot(np.sqrt(model_history.history['val_loss']), 'b' ,label='val')\n",
        "ax.set_xlabel(r'Epoch', fontsize=20)\n",
        "ax.set_ylabel(r'Loss', fontsize=20)\n",
        "ax.legend()\n",
        "ax.tick_params(labelsize=20)\n",
        "\n",
        "# Plot the accuracy\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
        "ax.plot(np.sqrt(model_history.history['accuracy']), 'r', label='train')\n",
        "ax.plot(np.sqrt(model_history.history['val_accuracy']), 'b' ,label='val')\n",
        "ax.set_xlabel(r'Epoch', fontsize=20)\n",
        "ax.set_ylabel(r'Accuracy', fontsize=20)\n",
        "ax.legend()\n",
        "ax.tick_params(labelsize=20)\n",
        "\n",
        "# Generate confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def decode_predictions(predictions):\n",
        "  temp = np.empty((len(predictions)))\n",
        "  i = 0\n",
        "  for prediction in predictions:\n",
        "    temp[i] = np.argmax(prediction, axis = 0)\n",
        "    i += 1\n",
        "  temp = label_encoder.inverse_transform(temp.astype(int))\n",
        "  return temp\n",
        "predictions = model.predict((start_test, grid_test))\n",
        "predictions = decode_predictions(predictions)\n",
        "# predictions = label_encoder.inverse_transform(predictions)\n",
        "confusion_matrix(np.array(predictions), np.array(move_test), labels=['left', 'right', 'up', 'down'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2srXjUkFRZ6c"
      },
      "outputs": [],
      "source": [
        "# load test grids\n",
        "filename = '/content/grids.h5'\n",
        "ip = pd.read_hdf(filename, key = 'df', mode='r')\n",
        "ip_grids = np.vstack(ip.apply(np.array).to_numpy()).reshape(100,50,50)\n",
        "ip_grids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_KnDTZek3gG"
      },
      "outputs": [],
      "source": [
        "# evaluate ml agent\n",
        "path = []\n",
        "\n",
        "def make_grid(probability, size):\n",
        "  grid = np.zeros((size, size))\n",
        "  if probability == 0:\n",
        "    return grid\n",
        "  for i in range(0, size - 1):\n",
        "    for j in range(0, size - 1):\n",
        "      p0 = random.uniform(0, 1)\n",
        "      if probability > p0:\n",
        "        grid[i][j] = 1\n",
        "\n",
        "    grid[0][0] = 0\n",
        "    grid[size - 1][size - 1] = 0\n",
        "    return grid\n",
        "\n",
        "\n",
        "def convert_state_to_grid(state):\n",
        "  g = make_grid(0, 50)\n",
        "  g[state[0]][state[1]] = 1\n",
        "  return g\n",
        "\n",
        "def is_valid_state(state, grid, check_grid = False):\n",
        "  if 0 > state[0] or state[0]> 49:\n",
        "    return False\n",
        "  if 0 > state[1] or state[1]> 49:\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "\n",
        "def get_pos_from_direction(pos, direction, grid):\n",
        "  if direction == 'stay':\n",
        "    return pos\n",
        "  \n",
        "  if direction == 'left':\n",
        "    new_pos = [pos[0], pos[1] - 1]\n",
        "    return new_pos if is_valid_state(new_pos, grid, True) else pos\n",
        "\n",
        "  if direction == 'right':\n",
        "    new_pos = [pos[0], pos[1] + 1]\n",
        "    return new_pos if is_valid_state(new_pos, grid, True) else pos\n",
        "\n",
        "  if direction == 'up':\n",
        "    new_pos = [pos[0] + 1, pos[1]]\n",
        "    return new_pos if is_valid_state(new_pos, grid, True) else pos\n",
        "\n",
        "  if direction == 'down':\n",
        "    new_pos = [pos[0] - 1, pos[1]]\n",
        "    return new_pos if is_valid_state(new_pos, grid, True) else pos\n",
        "\n",
        "\n",
        "def update_three(exp_grid, grid, pos):\n",
        "  neighbors = list()\n",
        "  neighbors.append(pos[0] + 1, pos[1])\n",
        "  neighbors.append(pos[0] - 1, pos[1])\n",
        "  neighbors.append(pos[0], pos[1] + 1)\n",
        "  neighbors.append(pos[0], pos[1] - 1)\n",
        "  for n in neighbors:\n",
        "    if is_valid_state(n, grid) and grid[n[0]][n[1]] == 1:\n",
        "      exp_grid[n[0]][n[1]] = 1\n",
        "\n",
        "\n",
        "def update_one(exp_grid, grid, pos):\n",
        "  neighbors = list()\n",
        "  neighbors.append([pos[0] + 1, pos[1]])\n",
        "  neighbors.append([pos[0] - 1, pos[1]])\n",
        "  neighbors.append([pos[0], pos[1] + 1])\n",
        "  neighbors.append([pos[0], pos[1] - 1])\n",
        "  for n in neighbors:\n",
        "    if is_valid_state(n, grid) and grid[n[0]][n[1]] == 1:\n",
        "      exp_grid[n[0]][n[1]] = 1\n",
        "\n",
        "\n",
        "def update_grid(exp_grid, grid, agent, pos):\n",
        "  if agent == 1:\n",
        "    update_one(exp_grid, grid, pos)\n",
        "  if agent == 3:\n",
        "    update_three(exp_grid, grid, pos)\n",
        "\n",
        "\n",
        "def run_agent(pos, grid, agent):\n",
        "  new_pos = pos\n",
        "  explored_grid = make_grid(0,50)\n",
        "  i=0\n",
        "  path.clear()\n",
        "  while (new_pos[0] != 49 or new_pos[1] != 49) and i < 500:\n",
        "    update_grid(explored_grid, grid, agent, new_pos)\n",
        "    new_pos = convert_state_to_grid(new_pos)\n",
        "    result = model.predict((new_pos.reshape((1, 50,50)), explored_grid.reshape((1, 50,50))))\n",
        "    new_pos = decode_predictions(result)\n",
        "    new_pos = get_pos_from_direction(pos, new_pos, grid)\n",
        "    pos = new_pos\n",
        "    path.append(new_pos)\n",
        "    i += 1\n",
        "\n",
        "def main_runner():\n",
        "  path_len = list()\n",
        "  i = 0\n",
        "  for main_grid in ip_grids:\n",
        "    run_agent([0,0], main_grid, 1)\n",
        "    print(\"Output\")\n",
        "    print(ip_grids[10])\n",
        "    print(path)\n",
        "    path_len.append(len(path))\n",
        "  print(path_len)\n",
        "\n",
        "main_runner()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Imitation Game 1st agent",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}